//#define POD_DEBUG

template<unsigned int dim>
coupling::noisereduction::POD<dim>::POD(
  const coupling::IndexConversion<dim> &indexConversion,
  const tarch::utils::MultiMDService<dim>& multiMDService
):
coupling::noisereduction::NoiseReduction<dim>(indexConversion, multiMDService, true),
_timeWindowSize(20),
_kMax(2),
_cycleCounter(0),
_spatialIndex(0),
_t(0),
_data(NULL),
_C(NULL),
_A(NULL),
_A_T(NULL),
_firstTraversal(true)
{
  int spatialSize = getLocalNumberMacroscopicCells(indexConversion);
  _data = new Eigen::MatrixXd[dim+1]; // separate data matrices for: mass, momentum0, momentum1, momentum2
  _C = new Eigen::MatrixXd[dim+1];
  _A = new Eigen::MatrixXd[dim+1];
  _A_T = new Eigen::MatrixXd[dim+1];
  for(unsigned int i=0;i<dim+1;i++){
    _data[i] = Eigen::MatrixXd::Constant(_timeWindowSize, spatialSize, (i==0)?1:0);
  }
}


template<unsigned int dim>
coupling::noisereduction::POD<dim>::~POD(){
  if (_data!=NULL){ delete [] _data; _data=NULL;}
  if (_C!=NULL){ delete [] _C; _C=NULL;}
  if (_A!=NULL){ delete [] _A; _A=NULL;}
  if (_A_T!=NULL){ delete [] _A_T; _A_T=NULL;}
}


template<unsigned int dim>
void coupling::noisereduction::POD<dim>::
beginProcessInnerMacroscopicCells(){
  _spatialIndex = 0;

  if(!_firstTraversal){
    for (unsigned int d = 0; d < dim+1; d++){
      // @todo write this in more efficient iterative form, 
      // updating just one single column instead of everything
      // and compute only lower triangular part!
      _C[d] = _data[d] * _data[d].transpose(); 

      #ifdef POD_DEBUG
      #if (COUPLING_MD_PARALLEL==COUPLING_MD_YES)
      for(unsigned int rank = 0; rank<coupling::noisereduction::NoiseReduction<dim>::_multiMDService.getLocalSize(); rank++){
        if(rank == coupling::noisereduction::NoiseReduction<dim>::_multiMDService.getLocalRank()){
      #endif
        std::cout << "Rank " << coupling::noisereduction::NoiseReduction<dim>::_multiMDService.getLocalRank()
          << ", _cycleCounter " << _cycleCounter << ": _data["<<d<<"] = " << _data[d] << std::endl;
        std::cout << "Rank " << coupling::noisereduction::NoiseReduction<dim>::_multiMDService.getLocalRank()
          << ", _cycleCounter " << _cycleCounter << ": _C["<<d<<"] = " << _C[d] << std::endl;
      #if (COUPLING_MD_PARALLEL==COUPLING_MD_YES)
        }
        MPI_Barrier(coupling::noisereduction::NoiseReduction<dim>::_multiMDService.getLocalCommunicator());
      }
      #endif
      #endif 
    }

    // @todo asynchronous allreduce! (but doesnt make sense currently, without interleaved computation)
    #if (COUPLING_MD_PARALLEL==COUPLING_MD_YES)
    const unsigned int count = _timeWindowSize*_timeWindowSize*(dim+1);
    double *send_data = new double[count];
    double *recv_data = new double[count];
    // Fill one common send buffer for all dimensions
    unsigned int index = 0;
    for (unsigned int d = 0; d < dim+1; d++)
      for(unsigned int i = 0; i < _timeWindowSize*_timeWindowSize; i++)
        send_data[index++] = _C[d].data()[i];
    MPI_Allreduce(send_data, recv_data, count, MPI_DOUBLE, MPI_SUM, 
      coupling::noisereduction::NoiseReduction<dim>::_multiMDService.getLocalCommunicator());
    for (unsigned int d = 0; d < dim+1; d++){
      Eigen::Map<Eigen::MatrixXd> map(&recv_data[d*_timeWindowSize*_timeWindowSize], _timeWindowSize, _timeWindowSize);
      _C[d] = map;  // copy assignment
    }
    delete [] send_data;
    delete [] recv_data;
    #endif

    for (unsigned int d = 0; d < dim+1; d++){
      #ifdef POD_DEBUG
      #if (COUPLING_MD_PARALLEL==COUPLING_MD_YES)
      for(unsigned int rank = 0; rank<coupling::noisereduction::NoiseReduction<dim>::_multiMDService.getLocalSize(); rank++){
        if(rank == coupling::noisereduction::NoiseReduction<dim>::_multiMDService.getLocalRank()){
      #endif
          std::cout << "Rank " << coupling::noisereduction::NoiseReduction<dim>::_multiMDService.getLocalRank()
            << ", _cycleCounter " << _cycleCounter << ": Communication finished" << std::endl;
          std::cout << "Rank " << coupling::noisereduction::NoiseReduction<dim>::_multiMDService.getLocalRank()
            << ", _cycleCounter " << _cycleCounter << ": _C["<<d<<"] = " << _C[d] << std::endl;
      #if (COUPLING_MD_PARALLEL==COUPLING_MD_YES)
        }
        MPI_Barrier(coupling::noisereduction::NoiseReduction<dim>::_multiMDService.getLocalCommunicator());
      }
      #endif
      #endif
      Eigen::SelfAdjointEigenSolver<Eigen::MatrixXd> solver(_C[d]);

      _A[d] = solver.eigenvectors().rightCols(_kMax);
      _A_T[d] = _A[d].transpose();
    }
  }
}


template<unsigned int dim>
void coupling::noisereduction::POD<dim>::
processInnerMacroscopicCell(
coupling::datastructures::MacroscopicCell<dim> &cell, const unsigned int &index){
  if(_firstTraversal){
    // save data into snapshot matrix
    _data[0](_t, _spatialIndex) = cell.getMacroscopicMass();
    for (unsigned int d = 0; d < dim; d++){    // (optimized compiler will unroll this loop)
      _data[d+1](_t, _spatialIndex) = cell.getMacroscopicMomentum()[d];
    }
  } else {
    // compute and store smoothed result
    Eigen::VectorXd phi_x = _A_T[0] * _data[0].col(_spatialIndex);
    cell.setMacroscopicMass((_A[0].row(_t) * phi_x).value());
    tarch::la::Vector<dim,double> mo_smooth;
    for (unsigned int d = 0; d < dim; d++){ // (optimized compiler will unroll this loop)
      phi_x = _A_T[d+1] * _data[d+1].col(_spatialIndex);
      mo_smooth[d] = (_A[d+1].row(_t) * phi_x).value();
    }
    cell.setMacroscopicMomentum(mo_smooth);
  }
  _spatialIndex++;
}


template<unsigned int dim>
void coupling::noisereduction::POD<dim>::
endProcessInnerMacroscopicCells(){
  if(!_firstTraversal){
    _cycleCounter++;
    _t = _cycleCounter%_timeWindowSize;
  }
  _firstTraversal = !_firstTraversal;
}

template<unsigned int dim>
unsigned int coupling::noisereduction::POD<dim>::getLocalNumberMacroscopicCells(const coupling::IndexConversion<dim> &indexConversion) const{
  const tarch::la::Vector<dim,unsigned int> localCells(indexConversion.getLocalNumberMacroscopicCells());
  unsigned int num = localCells[0]; for (unsigned int d = 1; d < dim; d++){ num = num * localCells[d]; }
  return num;
}

/*

* Latenz raus nehmen
- testen, stabilität
* verständnis für library untermauern
- tests / assertions 
- faster calculation of C, performance measurement
* bidirektionale kopplung später einschalten! für initialisierung
- cluster tests
- schon zb nach 90 / 100 MD timesteps filtern?

TODO

* Entwurf Gliederung

genauigkeit
- calc spacial sigma noise, plot profil
- one way coupling with filter results
- compare absolute/relative error: analytic vs filter, plot. compare for several snapshots, serveral k
- one plot per time step
- auswirkungen konfiguration -> stabilität der two way coupling
- oszillierender couette

- csv lb output, python script, cell select, automatisiert

SPÄTER

performance
- identitytransform -> no traversal
- overhead filter?
- scalability with / without filter, MD30 1,8,64   (possibly MD60/->MD120<-)

- multi instance sampling

TELKO Gliederung, Profilplots, TWC-Einschätzung, 16.05. 10:00 040-36949482

----------

TELKO OWC-Profilplot 23.05. 10:00 Uhr +49 40 460094-236


- bis FR Plots, Fig6a
- u_wall 0, TWC-Einschätzung

TELKO 30.05. 10:00 Uhr +49 40 460094-236

----------------------------

* Why don't we sample PDFs directly from MD?

* couette wall 0
* massetransfer abschalten, ränder periodic nie-transfer" mass-flux-west="yes" mass-flux-east="yes und
* zwischendurch updates
- massFlux Ecken surface?
- excessmass auf zellbasis?
- thermostat ausschalten ausprobieren
- shiftTimestep 0.5 ??

- draft kapitel  <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

TELKO 06.06. 10:00 Uhr +49 40 460094-236
************** Stability Deadline Mitte Juni *******************

-----------------------------

Heute: Profilplot (twc periodic) wie im paper, parameter dazu schreiben

zeitpunkt usher? -> vmtl unkritsch, evtl 20 timesteps
density mehr digits!!
usher
_offsetFromOuterBoundary = 0,5
partikel energie einfüge / lösch debugg
_offsetFromOuterBoundary = 0,0
_tolerance = ? 1.5 

periodic boundary + masstransfer - boundary force

masstransfer konst factor

outermost-overlap-layer="2" innermost-overlap-layer="3" ++ 

TELKO 13.06. 10:00 Uhr +49 40 460094-236

-----------------------------------------------

TELKO 20.06. 10:00 Uhr +49 40 460094-236

27.06 10? HH

*/
